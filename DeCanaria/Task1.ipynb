{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22a98f9",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Please be careful about the comment lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load job descriptions\n",
    "\n",
    "df_desc = pd.read_csv(\"data/indeed_us_job_description.csv\") # This part need adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load job links\n",
    "\n",
    "df_links = pd.read_csv(\"data/indeed_us_job_link_withdup.csv\") # This part need adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc57e6",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a0aec",
   "metadata": {},
   "source": [
    "### Description Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba840e",
   "metadata": {},
   "source": [
    "---\n",
    "#### Explore The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e70f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a7d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d218ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_desc.scrape_time.unique()) # I am not sure about the value of scrape_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8b388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc.job_label.isnull().unique() # whole column is null delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc.rating.isnull().unique() # whole column is null delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7511656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_desc.jk.unique()) # jk is the unique key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6babef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_desc.job_page_url.unique()) # job_page_url is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f6e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc.job_title.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96419a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc.company.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d63c2f",
   "metadata": {},
   "source": [
    "#### Run Cells Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98877003",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = df_desc[~df_desc.job_title.isnull()]\n",
    "\n",
    "# use the columns where job_title not null since we will use this column to group the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = df_desc[~df_desc.company.isnull()]\n",
    "\n",
    "# use the columns where company not null since we will use this column to group the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978bdfc",
   "metadata": {},
   "source": [
    "#### Do Not Run This Cell Unless You change the indexes of .iat method in the HTML Cleaning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3aa0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns does not have a value in the calculations\n",
    "\n",
    "del df_desc[\"job_label\"]\n",
    "del df_desc[\"rating\"]\n",
    "del df_desc[\"state\"] # can be reach from \"location\"\n",
    "del df_desc[\"zipcode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ad777",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c59b5",
   "metadata": {},
   "source": [
    "### Links Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9edaf",
   "metadata": {},
   "source": [
    "---\n",
    "#### Explore The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a0d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a879259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_links.job_page_url[0]\n",
    "df_links.job_page_url[1]\n",
    "\n",
    "# radius stands for how close is the job to you (in miles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72884169",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links.search_page_url[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c1d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_links[df_links[\"job_page_url\"].isnull()] # no null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7fe428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links[df_links[\"jk\"].isnull()] # no null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_links[\"jk\"].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e58767",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_links[\"job_page_url\"].unique()) # same length means jk is created from the job_page_url\n",
    "\n",
    "# I think this is unnecessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cfcc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_links.search_count.isnull().unique()) # whole columns is \"null\" delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16768150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_links[df_links[\"jk\"] == \"6516a3814e551ad1\"] \n",
    "\n",
    "# This matches with your note on Project file \" Note that the job link file contains multiple queries \n",
    "# from different zip codes for the same job key.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e12bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_links.scrape_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a6838",
   "metadata": {},
   "source": [
    "---\n",
    "#### Do Not Run This Cell Unless You change the indexes of .iat method in the HTML Cleaning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae948e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns does not have a value in the calculations\n",
    "\n",
    "del df_links[\"radius\"]\n",
    "del df_links['search_count']\n",
    "del df_links[\"zipcode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67177fc4",
   "metadata": {},
   "source": [
    "### 1.1 Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL\n",
    "df_total = pd.merge(df_links, df_desc, on=[\"jk\", \"job_page_url\"], suffixes=['_links', '_desc'], how=\"inner\" )\n",
    "\n",
    "# jk and job_page_url are the unique entries for data\n",
    "# outer not to lose any data I will eliminate the duplicates later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdee421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.info()\n",
    "\n",
    "# Be avare of the _x and _y columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ac177",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_total.job_description.isnull().unique()) # no empty job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a709230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.job_title.isnull().sum() # cleaned the null job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.company.isnull().sum() # cleaned the null company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b71e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.job_description.isnull().sum() # no None value for the description column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0b50f",
   "metadata": {},
   "source": [
    "### 1.2 Clean HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_desc.job_description[0]\n",
    "\n",
    "# Copy paste the list to an Editor to see a structural pattern in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow code vol.2\n",
    "# Alternative code block is below\n",
    "\n",
    "def clean_Job_Description(text):\n",
    "\n",
    "    clean_text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    return re.sub(r'\\s+', '', clean_text)\n",
    "\n",
    "\n",
    "for i in range(len(df_total[\"location\"])):\n",
    "    df_total.iloc[i,16] = clean_Job_Description(df_total.iloc[i,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550e1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.job_description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast code for cleaning the job description\n",
    "\n",
    "def clean_HTML(text):\n",
    "    clean_text = re.sub('<[^<]+?>', '', text)  # Remove HTML tags\n",
    "    clean_text = re.sub('\\n', ' ', clean_text)  # Replace \\n with a space\n",
    "    clean_text = re.sub('\\s+', ' ', clean_text)  # Replace multiple whitespaces with a single space\n",
    "    clean_text = re.sub('-', '', clean_text)  # Replace \"-\" with a space\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "for i in range(len(df_total[\"job_description\"])):\n",
    "    df_total.iat[i,12] = clean_HTML(df_total.iat[i,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e60f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.job_description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0653e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to run this cell unless you want to clean the \"location\" column, too.\n",
    "\n",
    "for i in range(len(df_total[\"location\"])):\n",
    "    try:\n",
    "        df_total.iat[i,16] = clean_HTML(df_total.iat[i,16])\n",
    "    except TypeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.location[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ea3e1",
   "metadata": {},
   "source": [
    "### 1.3 Remove Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to be adjusted\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'jk': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'value': ['A', 'B', 'C', 'B', 'D', 'E', 'A', 'F', 'C', 'G'],\n",
    "    'company': ['X', 'Y', 'Z', 'X', 'Y', 'Z', 'X', 'Y', 'Z', 'X']\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by 'company' and 'id'\n",
    "df_sorted = df.sort_values(['company', 'jk'])\n",
    "\n",
    "# Find duplicate values based on 'company'\n",
    "duplicates = df_sorted[df_sorted.duplicated(subset='company', keep=False)]\n",
    "\n",
    "# Group the duplicates by their company, and create a list of their IDs\n",
    "duplicates_by_company = duplicates.groupby('company')['jk'].apply(list)\n",
    "\n",
    "# Drop the duplicates and add a new column for the deleted IDs\n",
    "df_cleaned = df_sorted.drop_duplicates(subset='company', keep='first').merge(\n",
    "    duplicates_by_company.rename('jk_list').reset_index(),\n",
    "    on='company', how='left')\n",
    "\n",
    "# Fill missing values in the new column with an empty list\n",
    "df_cleaned['jk_list'] = df_cleaned['jk_list'].fillna(value={})\n",
    "\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9b87d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Codes below works a little slow!\n",
    "#### Run Cels Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9191b678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicates = df[df_total.duplicated(subset=['company','job_title','job_description'], keep=False)] # works slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4232f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_by_company = duplicates.groupby(['company','job_title','job_description'])['jk'].apply(list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.drop_duplicates(subset=['company','job_title','job_description']).merge(\n",
    "    duplicates_by_company.rename('jk_list').reset_index(),\n",
    "    on=['company','job_title','job_description'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6496f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final.jk_list.isnull()].info()\n",
    "\n",
    "# I would not expect Nan value in jk_list column since at least rows' own job key should be in the list.\n",
    "# I am in need of your feedback!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b911af97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df_final[\"jk_list\"])):\n",
    "    try:\n",
    "        df_final.iat[i,24] = list(set(df_final.iat[i,24]))\n",
    "    except TypeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf8a79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747b9bc",
   "metadata": {},
   "source": [
    "### 1.4 Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c29dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['index_dup'] = np.arange(1, df_final.shape[0] + 1) # fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"task1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303671f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd65a2",
   "metadata": {},
   "source": [
    "## Conceptual Questions\n",
    "\n",
    "Imagine that you receive daily data from 50,000 different job posting / employer sites. The data are in csv, json and other formats with different columns/ fields with approximate 20,000,000 daily job postings in volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad50b48",
   "metadata": {},
   "source": [
    "1) What type of database and platform would you use to process and store the data?\n",
    "\n",
    "**Answer**: A distributed database system will work for this much of data. It is more safe to use DDS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc05e0e",
   "metadata": {},
   "source": [
    "2) What technologies and tools would you use?\n",
    "\n",
    "**Answer:** I have no experience in DB technologies, yet we definitely need the tools that can handle large-scale datasets of different formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d500a6",
   "metadata": {},
   "source": [
    "3) How do you serve it to an end user (via some sort of dashboard/BI tool? Or would you develop something from scratch?\n",
    "\n",
    "**Answer:** I have used Tableau for learning purposes. It is designed for visualisation of large datasets and user-freiendly. Still, I believe if the code is yours you can achieve more. So, I would create a website to handle the data and visualize it using JS (React or Vue would be enough)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
